{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3a789e-04fb-459d-94a5-fd5254863e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import logging\n",
    "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex, StorageContext, load_index_from_storage\n",
    "\n",
    "#ログレベルの設定\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d92d6a-2569-4dca-bcfe-c24686240ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#環境変数からOpenAIのAPIキー読み込み\n",
    "load_dotenv(override=True)\n",
    "openai.api_key = os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593b9fa4-bef2-4df7-995a-800b4b5172ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_index(input_dir=\"./data\", save_dir=\"./storage\"):\n",
    "    \"\"\"input_dirのディレクトリ内のデータを基にインデックスを作成し、save_dirのディレクトリ内に保存する\n",
    "    \"\"\"\n",
    "    # ドキュメント読み込み\n",
    "    logging.info(\"----Start: loading documents-----\")\n",
    "    documents = SimpleDirectoryReader(input_dir=input_dir).load_data()\n",
    "    logging.debug(f\"documents: {documents}\")\n",
    "    logging.info(\"----End: loading documents-----\\n\")\n",
    "\n",
    "    # インデックスの作成：時間がかかるので注意\n",
    "    logging.info(\"----Start: making index-----\")\n",
    "    index = GPTVectorStoreIndex.from_documents(documents)\n",
    "    logging.info(f\"index:{index}\")\n",
    "    logging.info(\"----End: making index-----\\n\")\n",
    "\n",
    "    # インデックスの保存\n",
    "    logging.info(\"----Start: saving index-----\")\n",
    "    index.storage_context.persist(persist_dir=save_dir)\n",
    "    logging.info(\"----End: saving index-----\\n\")\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5175262-a71f-4423-90dc-5f73fca06345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_query_and_response(query_engine, query):\n",
    "    response = query_engine.query(query)\n",
    "    print(f\"query:{query}\")\n",
    "    print(f\"response:{response}\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e7aeed-4d7a-40ae-8d2a-43318d7db680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:----Start: loading index-----\n",
      "INFO:llama_index.indices.loading:Loading all indices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /tmp/llama_index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:----End: loading index-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "# 保存したインデックスがある場合には読み込み。なければインデックスの新規作成を実行\n",
    "try:\n",
    "    logging.info(\"----Start: loading index-----\")\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    logging.info(\"----End: loading index-----\\n\")\n",
    "except Exception as e:\n",
    "     logging.info(f\"Loading index failed.\")\n",
    "     logging.info(f\"Try to create index...\")\n",
    "     index = create_new_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f2ae14-a9d5-481f-a5b2-550c05b05dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:----Start: making query engine-----\n",
      "INFO:root:----End: making query engine-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query engineの作成\n",
    "logging.info(\"----Start: making query engine-----\")\n",
    "query_engine = index.as_query_engine()\n",
    "logging.info(\"----End: making query engine-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ff3f69-d27b-4aab-9dcb-776b5aa1f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クエリの設定\n",
    "query = \"Azure OpenAI Serviceで使用できるモデルの種類を教えてください\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e886a11-d05e-4b81-b767-aef0105c067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:Azure OpenAI Serviceで使用できるモデルの種類を教えてください\n",
      "response:基本モデルと微調整されたモデルの2種類のモデルがAzure OpenAI Serviceで使用できます。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='基本モデルと微調整されたモデルの2種類のモデルがAzure OpenAI Serviceで使用できます。', source_nodes=[NodeWithScore(node=TextNode(id_='b4b2883c-9a02-4545-9bb6-38f8dbe9f0cb', embedding=None, metadata={'page_label': '4', 'file_name': 'azure-ai-services-openai.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='93b2dfa8-0cf3-41c7-8989-0e9338332eab', node_type=None, metadata={'page_label': '4', 'file_name': 'azure-ai-services-openai.pdf'}, hash='44de5526b0376d780cf887294ab5e8fcf4cb0732007f1c1b41f2fa8edfa6121c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='deb7319e-63ba-4bb4-9743-1f3327b481ca', node_type=None, metadata={'page_label': '4', 'file_name': 'azure-ai-services-openai.pdf'}, hash='6e2f6536cbad461915f6e7b1c4fd5885e8472b7b8d763853bffed6296a478f33')}, hash='8c246cddca60826dfc14f794f1cfd5de7a8494f88cf86ea9f5af13b12ca7f9cb', text='Microsoft は、⼈を第⼀に考える原則に基づいて、 AI の発展に取り組んでいます。\\nAzure OpenAI で利⽤可能なもののような⽣成モデルは、⼤きな潜在的利点を持つが、\\n注意深く設計し、思慮深い緩和策を講じなければ、そのようなモデルは、不正確な、あ\\nるいは有害なコンテンツを⽣成する可能性さえあります。  マイクロソフトは、悪⽤や\\n意図しない危害から保護するために、申請者に明確に定義されたユースケースを⽰すこ\\nとを要求し、責任ある  AI 使⽤のためのマイクロソフトの原則 を取り⼊れ、顧客をサ\\nポートするためのコンテンツフィルターを構築し、オンボード顧客に責任ある  AI の実\\n装ガイダンスを提供するなど、多⼤な投資を⾏ってきました。\\nAzure OpenAI にアクセスするにはどうすればよいですか ?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.892089347819309), NodeWithScore(node=TextNode(id_='244d06d1-ad65-4f18-9a4b-5455c4171551', embedding=None, metadata={'page_label': '35', 'file_name': 'azure-ai-services-openai.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='30031f19-3b71-45b6-adb0-949f5bc36eb6', node_type=None, metadata={'page_label': '35', 'file_name': 'azure-ai-services-openai.pdf'}, hash='cd769a434c1ebddc326bae99f9b199ca2a58bd33c8b1aab2e133e08f00e3395a')}, hash='cd769a434c1ebddc326bae99f9b199ca2a58bd33c8b1aab2e133e08f00e3395a', text='Azure OpenAI の使⽤可能なモデルに関するガイド を参照してください。\\nどのリージョンで使⽤できるかについては、 Azure OpenAI の使⽤可能なモデルに関す\\nるガイドを参照してください。\\n基本モデルは、特定のユース  ケースに合わせてカスタマイズまたは微調整されていな\\nいモデルです。  微調整されたモデルは、基本モデルのカスタマイズされたバージョン\\nであり、モデルの重みがプロンプトの⼀意のセットに基づいてトレーニングされます。\\n微調整されたモデルを使⽤すると、完了プロンプトの⼀部としてコンテキスト内学習の\\nために詳細な例を提供しなくても、より多くのタスクでより良い結果を得ることができ\\nます。  詳細については、 微調整のガイドを参照してください。\\n100\\n現時点では、 API 応答時間サービス  レベル  アグリーメント  (SLA) は定義されていませ\\nん。 Azure OpenAI Service の  SLA の詳細については、「オンライン  サービスの  サービ\\nス レベル  アグリーメント  (SLA) 」ページを参照してください。モデルと微調整\\n使⽤可能なモデルは何ですか ?\\nモデルがどのリージョンで使⽤できるかはどこで\\n確認できますか ?\\n基本モデルと微調整されたモデルの違いは何です\\nか?\\n作成できる微調整されたモデルの最⼤数はいくつ\\nですか ?\\nAzur e OpenAI での  API 応答の  SLA はどのように\\nなっていますか ?\\n微調整されたモデル  デプロイが削除されたのはな\\nぜですか ?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8908343410226303)], metadata={'b4b2883c-9a02-4545-9bb6-38f8dbe9f0cb': {'page_label': '4', 'file_name': 'azure-ai-services-openai.pdf'}, '244d06d1-ad65-4f18-9a4b-5455c4171551': {'page_label': '35', 'file_name': 'azure-ai-services-openai.pdf'}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# クエリに対するレスポンスを表示\n",
    "send_query_and_response(query_engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed7ce0-809c-49da-8f4b-1e46dcc5ec03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
